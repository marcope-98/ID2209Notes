\chapter{Agent Theory}
\minitoc

Formal theory has arguably had little impact on the general practice of software development, however, they are relevant in agent-based systems because we need to be able to give a semantic to the architecture, languages and tools that we use (i.e. a meaning),\\
Without semantics, it is never clear exactly what is happening and why it works.

We need a theory to reach any kind of profound understanding the tools.

Formalization of agents has been used for 2 distinct purposes:
\begin{enumerate}
\item As internal specification language to be used by the agent in its reasoning or action
\item As external metalanguage to be used by the designer to specify, design and verify certain behavioural properties of agents situated in a dynamic environment.
\end{enumerate}
Agent theory gives both an overview of the ways in which an agetn is conceptualised and semantics to the architecrture, language and tools.

An agent model is needed to develop a theory of agents.
\section{Agents as intentional systems}
Theorists start from the notion of an agent as an intentional system.\\
So, agent theorists start with the view of agents as intentional systems: where agent's behaviour is explained in terms of attitudes.
\subsection{Attitudes}
Attitude represents a summary evaluation of a psycological object (e.g. oneself, other people, issue, plan, behaviour).\\
Attitudes are formed throughout the interaction with the surrounding environment\\
Attitudes help to manage individual's cognitive resources to deal with uncertainties of complex dynamic domains,

Formally an attitude is the use of a folk psychology, by which human behaviour is predicted and explained through the attribution of attitudes.\\
The attitudes employed in such folk psychological descriptions are called the intentional notions.\\
An approach is to describe agent's behaviour in terms of intentional systems, ``whose behaviour can be predicted by the method of attrivutring belief, desire and rational acumen''.\\
There exist first-order, second-order ,..., intentional systems.

Is it useful to consider agents (similar to humans) as intentional systems?
\begin{itemize}
\item It is legitimate when it express the same information about the machine that it expresses about a person
\item It is useful when it helps us understand the structure of the artifact
\item It perhaps never logically required even for humans
\item Ascription of mental qualities is most straightforward for machines of known structure but most useful for entities whose structure is incompletely known.
\end{itemize}

The following desciprion of a light switch is not appropriate because of we essentially understand the mechanism sufficiently to have a simpler, mechanistic description of its behaviour:\\
\say{Light switch is perfectly coherent to treat a light as a (very cooperative) agent with the capability of transmitting current at will, who invariably transmits current when it believes that we want it transmitted and not otherwise; flicking the switch is simply our way of communicating our desires}.

The more we know about a system the less we need to rely on intentional explanations of its behaviour.\\
An autonomous agent is a system that is most conveniently described by the intentional stance
\subsection{Theories of Attitudes}
We want to be able to design and build computer systems in terms of mentalistic notions.

Before we can do this, we need to identify a manageable subset of these attitudes and a model of how they interact to generate system behaviour. So first, which attitudes?

There exists 2 categories of attitudes:
\begin{enumerate}
\item \side{information attitudes}: such as belief and knowledge
\item \side{Pro-attitudes}: such as desire, intention, obligation, commitment, choice...
\end{enumerate}
\subsection{Study of Knowledge}
The study of knowledge tries to answer a series of open questions:
\begin{itemize}
\item What do we know?
\item What can we know?
\item What does it mean to say someone knows something?
\item What does an agent need to know in order to perform an action?
\item How does an agent know whether it knows enough to perform an action?
\item At what point does an agent know enough to stop gathering information and make a decision?
\end{itemize}

The study of knowledge tries to answer these questions both from an individual perspective and a group perspective.
\section{Foundation of formal logic}

A formal logic is a game for producing symbolic objects according to given rules.
The general syntax or alphabet of the formal logic includes the following notation:
\begin{itemize}
\item Variables ($X,Y, ...$)
\item Constants ($a, abc, 15, ...$)
\item Functors ($f/n$)
\item Predicate symbols ($p,q,...$)
\item Logical connectivities ($\neg, \lor, \land, \rightarrow, \iff$)
\item Quantifiers ($\forall, \exists$)
\item Auxiliary symbols
\end{itemize}

Given a term ($T$):
\begin{itemize}
\item Any constant in $A$ is in $T$
\item any variable in $A$ is in $T$
\item if $f$ is an n-ary functor in $A$ and $t_1, ... , t_n \in T$ then $f(t_1,..., t_n) \in T$
\end{itemize}

Let $T$ be the set of terms over alphabet $A$ and $F$ is the set of formulae:
\begin{itemize}
\item If $p$ is an n-ary predicate symbol and $t_1,...,t_n \in T$ then $p(t_1,...,t_n) \in F$
\item If $H$ and $G \in F$ so are 
\[\neg{H} \quad H\lor G \quad H\land G \quad H \rightarrow G \quad H\iff G\]
\item If $H\in F$ and $X$ is a variable then 
\missingfigure{not understood}
\end{itemize}
Formulae of the form $p(t_1,..., t_n)$ are called atomic formulae/

Interpretation:\\
An interpretation $T$ of alphabet $A$ is a non-empty domain $D$ and a mapping that associates:
\begin{itemize}
\item $c \in Const$ with an element $c_t \in D [Const \subseteq A]$
\item $f/n \in Func$ with an element 
\[f_t: D_n \rightarrow D [Func\subseteq A]\]
\item $p/m \in Pred$ with an element 
\[p_T \subseteq D_m (= D\times ... \times D) [Pred\subseteq A]\]
\end{itemize}
Under an interpretation, each term has a value and each atomic formula is either true or false.

Semantics of formulae:
\begin{itemize}
\item \side{Negation}\\
$\neg{A}$ is true if $A$ is false
\item \side{Conjunction}\\
$A\land B$ is true if both $A$ and $B$ are true
\item \side{Disjunction}\\
$A\lor B$ is true if either $A$ or $B$ is true
\item \side{Implication}\\
$A\rightarrow B$ is true if either $\neg{A}$ or $B$ are true
\item \side{Universal quantifier} $\forall X$\\
$A(x)$ is true if $A$ is true for every $X$
\item \side{Existential quantifier} $\exists X$\\
$A(x)$ is true if $A$ is true for some $X$
\item Propositional logic is the logic of connectives
\item Adding quantifiers give first-order logic, sometimes called predicate calculus
\item adding quantifiers over formula variables give Higher Order Logic
\end{itemize}

An interpretation $T$ is a model of a set of formulae $P$ iff every formulae of $P$ is true in $T$:
\begin{itemize}
\item every $P$ has infinitely many interpretations
\item Not every $P$ has a model
\item A set of formulae is unsatisfiable if it has no model
\item A set of formulae is satisfiable if it has at least one model
\end{itemize}

Logical consequence:\\
Let $P$ be a set of formulae. $F$ is a logical consequence of $P$ ($P|=F$) iff $F$ is true in every model of $P$.

Logical equivalence:\\
$F$ and $G$ are logically equivalent $(F \equiv G)$ iff $F$ and $G$ have the same truth value for every interpretation
\missingfigure{some equivalences from 26}
\subsection{Logical inference}
Reasoning can be seen as a process of manipulation of formulae, which from a given set of formular, called premises, produces a new formula, called the conclusion using inference rules
\missingfigure{Inference rules}

\section{Formalising attitudes}
Turns out that when we try to formalize attitudes or intentional systems, the application of formal logic makes them referentially opaque: hence standard substitution rules of first-order logic do not apply (intentional notions are not truth functional)

There are 2 sorts of probelms to be addressed in developing a logical formalism for intentional notions:
\begin{enumerate}
\item Syntactic
\item Semantic
\end{enumerate}
With respect to the syntactic problem, there are two fundamental approaches:
\begin{enumerate}
\item Use a modal language, which contains modal operators, which are applied to formulae
\item use a meta-language: a first-order language containing terms that denote formulae of some other object language
\end{enumerate}
Likewise, two basic approaches to the semantic problem:
\begin{enumerate}
\item Possible worlds semantics
\item Interpreted symbol structures
\end{enumerate}
Of the four combination we will focus on the possible world semantics and modal logic
\subsection{Possible worlds}
The intuitive idea behind possible worlds is that besides the true states of affairs there are a number of states of affairs or ``worlds''.\\
Each world represents one state of affairs.\\
Given his current information, an agent may not be able to tell which of a number of possible worlds describes the actual state of affairs. Consequently, an agent's beliefs can be characterized as a set of possible worlds.

Moreover, the possible worlds approach can be represented using modal logic.

The main advantages of such approach is:
\begin{itemize}
\item Mathematical theory is appealing
\item Neutral on the subject of the cognitive structure
\end{itemize}

Consider an agent playing a card game, who possessed the ace of spades. How could the agent deduce what cards were possessed by the opponents?\\
First, calculate all the various ways that the pack of cards could possibly have been distributed among the various players\\
Then, systematically eliminate all those configurations which are not possible given what the agent knows (any configuration in which the agent did not possess the ace of spades could be rejected).\\
Each configuration remaining after this is a world: a state of affairs considered possible given what the agent knows (aka epistemic alternatives).\\
We can notice that something true in all our agent's possibilities is known by the agent.
\subsection{Modal Logic}
Possible worlds can be incorpored into the semantic framework of modal logic.
In fact, modal logic was used by philosophers to investigate different modes of truth.

In the study of agents, it is used to give meaning to concepts such as belief and knowledge.\\
Modal logic can be considered as the logical theory of necessity and possibilty.\\
It is essentially classical propositional logic extended by two operators:
\begin{itemize}
\item \side{Necessity } ($\square$)
\item \side{Possibility} ($\bDiamond$)
\end{itemize}
Let $S=\{p,q,...\}$ be a set of atomic propositions
\begin{itemize}
\item If $p\in S$ then $p$ is a formula
\item If $A, B$ are formulae, then so are $\neg{A}$ and $A \land B$
\item if $A$ is a formulae, then so are $\square A$ and $\bDiamond A$
\end{itemize}
other connectives can be expressed by abbreviation:
\[F\rightarrow G \equiv \neg{F} \lor G q\qquad \neg{(F\land G)} \equiv \neg{F} \lor \neg{G}\]
The duality of operators:
\[\square A \equiv \neg{\bDiamond} \neg{A}\qquad \bDiamond A \equiv \neg{\square} \neg{A}\]
Two basic properties:
\begin{enumerate}
\item \side{K axiom schema}
\[\square (A\rightarrow B ) \rightarrow (\square A \rightarrow \square B)\]
\item \side{Necessitation rule}: if A is valid, then $\square A$ is valid
\end{enumerate}

The semantics of modal logic is traditionally given in terms of possible worlds:
\begin{itemize}
\item The formula $\square A$ is true if $A$ is true in every world accessible from the current world
\item The formula $\bDiamond A$ is true if $A$ is true in at least one world accessible from the current world
\end{itemize}
With sets of wolrds as primitive, the structure of the model is captured by relating the different worlds via a binary accessibility relation

Formalizing possible worlds vis Kripke structure:
\[(S, \pi, K_1, ... , K_n\]
\begin{itemize}
\item $S$ is the set of possible worlds
\item $\pi$ is the set of formulae true at a world
\item $K_i$ is a binary accebility relation on $S$ (a set of pairs of elements of $S$)
\end{itemize}
\missingfigure{40}
Possible properties of accessibility relations:
\begin{itemize}
\item \side{Reflexive}\\
For all $s\in S$, we have $(s,s)\in K$
\item \side{Symmetric}\\
For all $s,t \in S$, we have $(s,t)\in K \iff (t,s)\in K$
\item \side{Transitive}\\
For all $s,t,u \in S$, we have that if 
\[(s,t)\in K \qquad \land (t,u)\in K \quad\text{then}\quad (s,u)\in K\]
\item \side{Serial}\\
For all $s\in S$ there is some $t$ such that $(s,t)\in K$
\item \side{Euclidean}\\
For all $s,t,u\in S$ whenver
\[(s,t)\in K \quad\land\quad (s,u)\in K\quad\text{then}\quad (t,u)\in K\]
\end{itemize}
If $K$ is reflexive and Euclidean, then $K$ is symmetric and transitive\\
If $K$ is symmetric and transitive, then $K$ is Euclidean

The following are equivalent:
\begin{itemize}
\item K is reflexive, simmetric and transitive
\item K is symmetric, transitive and serial 
\item K is reflexive and Euclidean
\end{itemize}

Properties of accessibility relation are represented by axiom schemas:
\begin{itemize}
\item \side{T axiom}: corresponds to reflexive accessibility relation
\[\square A \rightarrow A\]
\item \side{D axiom}: corresponds to serial accessibility relation
\[\square A \rightarrow \bDiamond A\]
\item \side{4 axiom}: corresponds to transitive accessibility relation
\[\square A \rightarrow \square\square A\]
\item \side{5 axiom}: corresponds to Euclidean accessibility relation
\[\bDiamond A\rightarrow ]square \bDiamond A\]
\end{itemize}
\section{Logic of Knowledge}

The formula $\square A$ is read ``It is known that A'' of ``agent knows A'' and denoted as K\\
For group knowledge we have an indexed set of modal operators:
\[K_1, ...., K_n \quad\text{for }\square\]
In this frame of reference $K_1 A$ is read as ``agent1 knows A''

As a consequence we can interpret the 4 axiom of accessibility relation:
\begin{itemize}
\item T axiom (Knowledge axiom) $K_i A \rightarrow A$\\
\say{what is known is true}
\item D axiom $K_i A \rightarrow \neg{K_i} \neg{A}$\\
\say{If agent i knows A then agent i does not know $\neg{A}$}
\item 4 axiom (positive introspection) $K_i A \rightarrow K_i K_i A$\\
\say{If agent i knows A then agents i knows that it knows A}
\item 5 axiom (negative introspection) $\neg{K_i} \neg{A}\rightarrow K_i \neg{K_i}\neg{A}$\\
\say{agent i is aware of what it does not know} 
\end{itemize}

Knowledge is often defined as true belief, i.e. an agent knows A if the agent believs A and A is true.\\
Axioms KTD45 are often chosen as a logic of knowledge\\
Axioms KD45 are often chosen as a logic of belief\\

How well does normal modal logic serves as a logic of knowledge and belief?\\
Consider the K axiom and the necessitation rule:
\begin{itemize}
\item Necessitation rule: an agent knows all valid formulae (an agent will have an infinite number of items of knowledge)\\
If $A$ is valid, then $\square A$ is valid
\item K axiom: agent's knowledge is closed under implication
\[\square(A\rightarrow B) \rightarrow (\square A \rightarrow \square B)\]
\end{itemize}

\begin{itemize}
\item \side{Logical omniscience}: knowing all truth of logic
\item \side{Logical omniscience problem}: constituted by that of knowin all valid formulae and that of knowledge/belief being closed under consequence (must know all logical consequences of one's knowledge or belief)
\item Disadvantages of using possible world semantics for agents are:
\begin{itemize}
\item Agents believe/know all valid formulae
\item Agents' beliefs/knowledge are closed under logical consequence
\end{itemize}
\end{itemize}

Other approaches:
\begin{enumerate}
\item \side{Levesque}\\
In order to avoid logical omniscience problem a distinctrion is made between explicit and implicit belief
\item \side{Konolige}\\
Deduction model of belief\\
The deduction model defines a belief system as a tuple
\[d=(\Delta, \rho)\]
containing a base set of formulae in some internal, logical language of belief and a set of deduction rules (may be incomplete) for deriving new beliefs\\
Agent with such a belief system believe $A$ if $A$ can be derived from its base set using its deduction rules
\end{enumerate}


\section{BDI architecture}
Systems and formalisms that give primary importance to intentions are often referred to as \side{BDi architecture}\\
Formalization of intentions based on branching-time possible worlds future and single past model\\
Crucial elements are :
\begin{itemize}
\item Intentions are treated on a pair with beliefs and goals
\item Distinguishes between choices and the possibilities of the different outcomes of actions
\item Interrelationship between belief, goals and intentions are specified (goals are consisten desires of an agent)
\end{itemize}
Informal semantics:
\begin{itemize}
\item The world is modeled by using a temporal structure with a branching time future and a single past, this is called a \side{time tree}
\item A particular time point in a particular world is a \side{situation}
\item Event types transform one time point to another
\item Primitive events are those events directly performable by the agent and uniquely determine the next time point
\item The brances in a time tree represent the choices available to an agent
\end{itemize}
Uses 2 modal operators:
\begin{itemize}
\item \side{Optional}: a path formuyal formula is said to be optional if, at a particular time point in a time tree, it is true of at least one path emanating from the point
\item \side{Inevitable}: a path formula is said to be inevitable if it true of all paths emanating from that point
\end{itemize}
\side{Temporal operators}: next eventually always, until\\
A combination of these modalities can be used to describe the options available to an agent\\
\missingfigure{55}

Formal definitions:
\begin{enumerate}
\item \side{Beliefs}\\
In each situtation a set of belief-accessible worlds is associate. Those worlds that the agent believes to be possible.\\
Each belief-accessible world is a time-tree
\item \side{Goals/Desires}\\
For each situation a set of goal-accessible worlds is associated. Those rep[resent the goals of the agent.\\
Goals are chosen desires of the agent that are consisten and agent should believe that the goal is achievable; goals must be compatible with beliefs.\\
For each belief-accessible world w in time t, there must be a goal accessible sub-worlds of w at time t
\item \side{Intentions}\\
Intentions are represented by a set of intention-accessible worlds\\
These worlds are ones that an agent has committed to attempt to realize\\
The intention-accessible worlds of an agent must be compatible with its goal-accessible worlds\\
For each goal-accessible world w in time t, there must be an intention accessible sub world of w at time t
\end{enumerate}
\missingfigure{57 58}